import parselmouth
import numpy as np


def extract_f0_and_formants(audio_path, max_formant=5500.0):
    """
    åŒæ—¶æå– F0 å’Œå‰ä¸‰ä¸ªå…±æŒ¯å³°ï¼ˆF1, F2, F3ï¼‰ã€‚

    å‚æ•°:
        audio_path (str): éŸ³é¢‘è·¯å¾„
        max_formant (float): æœ€å¤§å…±æŒ¯å³°é¢‘ç‡ï¼ˆHzï¼‰
            - ç”·æ€§: 5000
            - å¥³æ€§/å„¿ç«¥: 5500

    è¿”å›:
        dict: åŒ…å« F0_median, F1, F2, F3
    """
    sound = parselmouth.Sound(audio_path)

    # === æå– F0 ===
    pitch = sound.to_pitch(time_step=0.01, pitch_floor=50, pitch_ceiling=600)
    f0_vals = pitch.selected_array['frequency']
    valid_f0 = f0_vals[f0_vals != 0]
    f0_median = np.median(valid_f0) if len(valid_f0) >= 10 else None

    # === æå–å…±æŒ¯å³° ===
    formant = sound.to_formant_burg(
        time_step=0.01,
        max_number_of_formants=5,
        maximum_formant=max_formant,
        window_length=0.025,
        pre_emphasis_from=50.0
    )

    f1_list, f2_list, f3_list = [], [], []
    for t in np.arange(0.01, sound.duration, 0.01):
        f1 = formant.get_value_at_time(1, t)
        f2 = formant.get_value_at_time(2, t)
        f3 = formant.get_value_at_time(3, t)
        if f1 > 0 and f2 > 0 and f3 > 0:
            f1_list.append(f1)
            f2_list.append(f2)
            f3_list.append(f3)

    return {
        'f0_median': f0_median,
        'F1': np.median(f1_list) if f1_list else None,
        'F2': np.median(f2_list) if f2_list else None,
        'F3': np.median(f3_list) if f3_list else None
    }


def classify_speaker_with_formants(features):
    """
    åŸºäº F0 + å…±æŒ¯å³°è”åˆåˆ¤æ–­è¯´è¯äººç±»å‹ã€‚
    """
    f0 = features['f0_median']
    f1, f2, f3 = features['F1'], features['F2'], features['F3']

    if f0 is None or f1 is None:
        return "Unknown (insufficient voiced speech)"

    # è§„åˆ™ 1: å…ˆç”¨ F0 åˆç­›
    if f0 < 150:
        speaker_type = "Male"
    elif f0 < 220:
        speaker_type = "Female"
    else:
        speaker_type = "Child"

    # è§„åˆ™ 2: ç”¨å…±æŒ¯å³°éªŒè¯ï¼ˆå°¤å…¶åŒºåˆ†é«˜éŸ³ç”·å£° vs å¥³å£°ï¼‰
    if speaker_type == "Male" and f2 > 1600:
        # ç”·å£° F2 å¾ˆå°‘ >1600ï¼Œè‹¥é«˜ï¼Œå¯èƒ½æ˜¯å¥³å£°
        speaker_type = "Female"
    elif speaker_type in ["Female", "Child"] and f2 > 2200:
        # F2 > 2200 æå¯èƒ½æ˜¯å„¿ç«¥
        speaker_type = "Child"
    elif speaker_type == "Child" and f2 < 1800:
        # å„¿ç«¥ F2 é€šå¸¸ >1800ï¼Œè‹¥ä½ï¼Œå¯èƒ½æ˜¯å¥³å£°
        speaker_type = "Female"

    return speaker_type


def analyze_speaker(audio_path, gender_hint=None):
    """
    ä¸»å‡½æ•°ï¼šåˆ†æéŸ³é¢‘å¹¶è¾“å‡ºç»“æœã€‚

    å‚æ•°:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        gender_hint: å¯é€‰æç¤ºï¼ˆ"male", "female", "child"ï¼‰ï¼Œç”¨äºè‡ªåŠ¨é€‰æ‹© max_formant
    """
    # è‡ªåŠ¨é€‰æ‹© max_formantï¼ˆæå‡å…±æŒ¯å³°ä¼°è®¡ç²¾åº¦ï¼‰
    if gender_hint == "male":
        max_formant = 5000.0
    else:
        max_formant = 5500.0  # é»˜è®¤ç”¨äºå¥³/å„¿ç«¥

    features = extract_f0_and_formants(audio_path, max_formant)
    speaker_type = classify_speaker_with_formants(features)

    print(f"ğŸ”Š éŸ³é¢‘: {audio_path}")
    print("-" * 50)
    print(f"{'ç‰¹å¾':<10} | {'å€¼ (Hz)':<10}")
    print("-" * 50)
    print(f"{'F0 (ä¸­ä½)':<10} | {features['f0_median']:<10.1f}" if features['f0_median'] else "F0         | N/A")
    print(f"{'F1':<10} | {features['F1']:<10.1f}" if features['F1'] else "F1         | N/A")
    print(f"{'F2':<10} | {features['F2']:<10.1f}" if features['F2'] else "F2         | N/A")
    print(f"{'F3':<10} | {features['F3']:<10.1f}" if features['F3'] else "F3         | N/A")
    print("-" * 50)
    print(f"ğŸ¯ é¢„æµ‹è¯´è¯äººç±»å‹: {speaker_type}")

    return speaker_type, features


# ======================
# ä½¿ç”¨ç¤ºä¾‹
# ======================
if __name__ == "__main__":
    # åˆ†æä¸€æ®µéŸ³é¢‘
    from configs.config import audiofile
    result, feats = analyze_speaker(audiofile)  # è‹¥çŸ¥é“å¤§è‡´ç±»åˆ«ï¼Œå¯ä¼  hint